# Guide d'Impl√©mentation Complet - Syst√®me RAG Agentic HAProxy 3.2

Ce guide fournit des instructions d√©taill√©es pour installer, configurer et d√©ployer le syst√®me RAG agentic pour la documentation HAProxy 3.2.

## üìã Table des Mati√®res

1. [Vue d'ensemble](#vue-densemble)
2. [Pr√©requis](#pr√©requis)
3. [Installation](#installation)
4. [Configuration](#configuration)
5. [Pipeline de Donn√©es](#pipeline-de-donn√©es)
6. [Lancement du Chatbot](#lancement-du-chatbot)
7. [Tests](#tests)
8. [D√©pannage](#d√©pannage)
9. [Architecture](#architecture)
10. [M√©triques et Performance](#m√©triques-et-performance)

---

## Vue d'ensemble

Le syst√®me RAG agentic HAProxy 3.2 est un assistant intelligent bas√© sur la documentation officielle HAProxy 3.2. Il utilise:

- **LangGraph** pour l'orchestration de l'agent
- **ChromaDB** pour le stockage vectoriel
- **Ollama** pour les embeddings et le LLM
- **Gradio 6.6.0** pour l'interface utilisateur
- **Strat√©gie parent/child** pour le chunking

### Architecture

```
Documentation HAProxy 3.2 (Web)
    ‚Üì Scraping
Pages avec hi√©rarchie (data_agentic/scraped_pages.json)
    ‚Üì Analyse hi√©rarchie
Rapport parent/child (data_agentic/hierarchy_report.json)
    ‚Üì Chunking
Parents (parent_store/*.json) + Children (data_agentic/chunks_child.json)
    ‚Üì Indexation
Vector Store ChromaDB (index_agentic/chroma_db/)
    ‚Üì Agent LangGraph
Outils: search_child_chunks, retrieve_parent_chunks, validate_haproxy_config
    ‚Üì Chatbot Gradio
Interface utilisateur sur port 7861
```

---

## Pr√©requis

### Syst√®me
- Windows 10/11, macOS, ou Linux
- Python 3.11 ou sup√©rieur
- 8 Go RAM minimum (16 Go recommand√©)
- 10 Go d'espace disque libre

### Logiciels requis

#### 1. Python 3.11+
```bash
# V√©rifier la version de Python
python --version

# Si Python n'est pas install√©, t√©l√©charger depuis:
# https://www.python.org/downloads/
```

#### 2. uv (Gestionnaire de paquets Python)
```bash
# Installer uv
pip install uv

# V√©rifier l'installation
uv --version
```

#### 3. Ollama (LLM et Embeddings)
```bash
# T√©l√©charger Ollama depuis:
# https://ollama.com/download

# Installer Ollama (Windows)
# Ex√©cuter le fichier .msi t√©l√©charg√©

# V√©rifier l'installation
ollama --version
```

#### 4. Mod√®les Ollama requis
```bash
# Pull le mod√®le LLM
ollama pull qwen3:latest

# Pull le mod√®le d'embeddings
ollama pull qwen3-embedding:8b

# V√©rifier les mod√®les install√©s
ollama list
```

---

## Installation

### 1. Cloner le repository
```bash
# Si ce n'est pas d√©j√† fait
cd c:/GIT/fork/haproxy-dataset-generator
```

### 2. Installer les d√©pendances Python
```bash
# Naviguer dans le r√©pertoire du syst√®me agentic
cd agentic_rag

# Installer les d√©pendances avec uv
uv sync

# V√©rifier l'installation
uv pip list
```

### 3. V√©rifier la structure du projet
```bash
# La structure devrait ressembler √†:
agentic_rag/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ 00_rebuild_agentic.py
‚îú‚îÄ‚îÄ 01_scrape_verified.py
‚îú‚îÄ‚îÄ 02_chunking_parent_child.py
‚îú‚îÄ‚îÄ 03_indexing_chroma.py
‚îú‚îÄ‚îÄ 04_agentic_chatbot.py
‚îú‚îÄ‚îÄ config_agentic.py
‚îú‚îÄ‚îÄ pyproject_agentic.toml
‚îú‚îÄ‚îÄ README_AGENTIC.md
‚îú‚îÄ‚îÄ app/
‚îú‚îÄ‚îÄ rag_agent/
‚îú‚îÄ‚îÄ db/
‚îú‚îÄ‚îÄ scraper/
‚îú‚îÄ‚îÄ tests/
‚îú‚îÄ‚îÄ data_agentic/
‚îú‚îÄ‚îÄ index_agentic/
‚îî‚îÄ‚îÄ parent_store/
```

---

## Configuration

### 1. Configuration Ollama

V√©rifier que Ollama est en cours d'ex√©cution:
```bash
# D√©marrer Ollama (si n√©cessaire)
ollama serve
```

### 2. Configuration du syst√®me

Le fichier [`config_agentic.py`](agentic_rag/config_agentic.py) contient toutes les configurations. Les valeurs par d√©faut sont g√©n√©ralement suffisantes.

Param√®tres cl√©s:
```python
# Mod√®les
LLM_MODEL = "qwen3:latest"
EMBEDDING_MODEL = "qwen3-embedding:8b"

# Chunking
CHILD_CHUNK_SIZE = 500
CHILD_CHUNK_OVERLAP = 80
MIN_PARENT_SIZE = 100
MAX_PARENT_SIZE = 4000

# Retrieval
DEFAULT_K_CHILD = 5
DEFAULT_K_MMR = 5
MMR_FETCH_K = 20
SCORE_THRESHOLD = 0.7

# Gradio
SERVER_PORT = 7861
```

### 3. Personnalisation (optionnel)

Si vous souhaitez modifier la configuration:
```bash
# √âditer le fichier de configuration
code agentic_rag/config_agentic.py
```

---

## Pipeline de Donn√©es

Le pipeline de donn√©es se compose de 3 phases principales:

### Phase 1: Scraping + Validation

Scrape la documentation HAProxy 3.2 et valide les r√©sultats.

```bash
# Ex√©cuter la phase 1
cd agentic_rag
uv run python 01_scrape_verified.py
```

**Sortie attendue:**
```
=== Phase 1: Scraping + Validation ===

1. Scraping des pages HAProxy 3.2...
‚úì Scrap√© X pages

2. Analyse de la hi√©rarchie...
‚úì Rapport de hi√©rarchie g√©n√©r√©

3. Comparaison avec le projet principal...
‚úì Couverture: 98.5%

‚úì Phase 1 termin√©e avec succ√®s!
  - Pages scrap√©es: X
  - Couverture: 98.5%

Validation humaine requise avant de passer √† Phase 2.
```

**Fichiers g√©n√©r√©s:**
- `data_agentic/scraped_pages.json` - Pages scrap√©es
- `data_agentic/hierarchy_report.json` - Rapport de hi√©rarchie
- `data_agentic/scraping_diff_report.json` - Rapport de comparaison

### Phase 2: Chunking Parent/Child

Effectue le chunking hi√©rarchique parent/child.

```bash
# Ex√©cuter la phase 2
uv run python 02_chunking_parent_child.py
```

**Sortie attendue:**
```
=== Phase 2: Chunking Parent/Child ===

1. Chargement des donn√©es scrap√©es...
‚úì X pages charg√©es

2. Chunking hi√©rarchique...
‚úì X parents cr√©√©s
‚úì X enfants cr√©√©s

3. Sauvegarde des chunks enfants...
‚úì Chunks sauvegard√©s dans data_agentic/chunks_child.json

=== Statistiques ===
Parents - Taille moyenne: 1500 chars
Parents - Min: 100, Max: 4000
Children - Taille moyenne: 500 chars
Children - Min: 100, Max: 800

‚úì Phase 2 termin√©e avec succ√®s!
```

**Fichiers g√©n√©r√©s:**
- `parent_store/*.json` - Chunks parents
- `data_agentic/chunks_child.json` - Chunks enfants

### Phase 3: Indexation ChromaDB

Indexe les chunks dans ChromaDB.

```bash
# Ex√©cuter la phase 3
uv run python 03_indexing_chroma.py
```

**Sortie attendue:**
```
=== Phase 3: Indexation ChromaDB ===

1. Chargement des chunks enfants...
‚úì X chunks charg√©s

2. Initialisation des embeddings (qwen3-embedding:8b)...
‚úì Embeddings initialis√©s

3. Initialisation de ChromaDB...
‚úì Collection cr√©√©e

4. Nettoyage de la collection existante...
‚úì Collection cr√©√©e

5. Cr√©ation des documents LangChain...
‚úì X documents cr√©√©s

6. Indexation des documents...
‚úì Documents index√©s

7. V√©rification de l'indexation...
‚úì X documents dans la collection

8. Test de recherche...
‚úì 3 r√©sultats pour la requ√™te de test

‚úì Phase 3 termin√©e avec succ√®s!
  - Documents index√©s: X
  - Collection: haproxy_child_chunks
  - Chemin: index_agentic/chroma_db/
```

**Fichiers g√©n√©r√©s:**
- `index_agentic/chroma_db/` - Base de donn√©es vectorielle ChromaDB

### Pipeline complet

Pour ex√©cuter tout le pipeline en une fois:

```bash
# Ex√©cuter tout le pipeline
uv run python 00_rebuild_agentic.py
```

Le pipeline vous demandera une confirmation avant chaque phase.

---

## Lancement du Chatbot

Une fois le pipeline termin√©, lancez le chatbot:

```bash
# Lancer le chatbot
uv run python 04_agentic_chatbot.py
```

**Sortie attendue:**
```
=== HAProxy 3.2 Agentic RAG Chatbot ===
Port: 7861
D√©marrage de l'interface Gradio...

Running on local URL:  http://0.0.0.0:7861

To create a public link, set `share=True` in `launch()`.
```

### Acc√©der au chatbot

Ouvrez votre navigateur et acc√©dez √†:
```
http://localhost:7861
```

### Utilisation du chatbot

1. Posez une question sur HAProxy 3.2
2. L'agent analysera votre question
3. Il utilisera les outils de retrieval pour trouver les informations pertinentes
4. Il vous fournira une r√©ponse avec les sources cit√©es

**Exemples de questions:**
- "Comment configurer un frontend dans HAProxy ?"
- "Quels sont les param√®tres globaux de HAProxy ?"
- "Comment activer SSL dans HAProxy ?"
- "Qu'est-ce qu'un backend dans HAProxy ?"

---

## Tests

### Ex√©cuter tous les tests

```bash
# Ex√©cuter tous les tests
uv run pytest

# Avec sortie d√©taill√©e
uv run pytest -v

# Avec couverture de code
uv run pytest --cov=agentic_rag --cov-report=html
```

### Tests individuels

```bash
# Tests du scraper
uv run pytest agentic_rag/tests/test_scraper_alignment.py -v

# Tests du chunking
uv run pytest agentic_rag/tests/test_chunking.py -v

# Tests du retrieval
uv run pytest agentic_rag/tests/test_retrieval.py -v

# Tests du graphe
uv run pytest agentic_rag/tests/test_graph_flow.py -v

# Tests E2E
uv run pytest agentic_rag/tests/test_end_to_end.py -v
```

### R√©sultats attendus

Tous les tests devraient passer (27 tests):
```
======================== test session starts =========================
collected 27 items

tests/test_scraper_alignment.py .....                          [ 18%]
tests/test_chunking.py .....                                  [ 37%]
tests/test_retrieval.py .....                                 [ 55%]
tests/test_graph_flow.py .......                               [ 81%]
tests/test_end_to_end.py .....                                [100%]

========================= 27 passed in X.XXs =========================
```

---

## D√©pannage

### Probl√®me: Ollama n'est pas accessible

**Sympt√¥me:**
```
ConnectionError: Cannot connect to Ollama server
```

**Solution:**
```bash
# V√©rifier si Ollama est en cours d'ex√©cution
ollama ps

# D√©marrer Ollama
ollama serve

# Dans un autre terminal, v√©rifier
curl http://localhost:11434/api/tags
```

### Probl√®me: Mod√®le Ollama non trouv√©

**Sympt√¥me:**
```
Error: model 'qwen3:latest' not found
```

**Solution:**
```bash
# Pull le mod√®le manquant
ollama pull qwen3:latest
ollama pull qwen3-embedding:8b

# V√©rifier les mod√®les install√©s
ollama list
```

### Probl√®me: ChromaDB ne peut pas cr√©er la collection

**Sympt√¥me:**
```
Error: Cannot create collection
```

**Solution:**
```bash
# Supprimer le dossier ChromaDB existant
rm -rf agentic_rag/index_agentic/chroma_db/

# Relancer l'indexation
uv run python 03_indexing_chroma.py
```

### Probl√®me: Le chatbot ne d√©marre pas

**Sympt√¥me:**
```
Error: Port 7861 already in use
```

**Solution:**
```bash
# Changer le port dans config_agentic.py
# SERVER_PORT = 7862

# Ou arr√™ter le processus utilisant le port 7861
# Sur Windows:
netstat -ano | findstr :7861
taskkill /PID <PID> /F
```

### Probl√®me: Tests √©chouent

**Sympt√¥me:**
```
FAILED tests/test_retrieval.py::test_chroma_manager_delete_collection
```

**Solution:**
```bash
# Nettoyer les fichiers temporaires
rm -rf agentic_rag/.ruff_cache/
rm -rf agentic_rag/index_agentic/chroma_db/

# Relancer les tests
uv run pytest
```

---

## Architecture

### Composants principaux

#### 1. Module `rag_agent/` (LangGraph)

- **graph.py**: Construction du graphe LangGraph
- **graph_state.py**: √âtat du graphe (State)
- **nodes.py**: N≈ìuds du graphe (summarize, analyze, agent, human_input)
- **edges.py**: Routing conditionnel
- **tools.py**: Outils de retrieval (search_child_chunks, retrieve_parent_chunks, validate_haproxy_config)
- **schemas.py**: Sch√©mas Pydantic v2
- **prompts.py**: Prompts syst√®me

#### 2. Module `db/` (Bases de donn√©es)

- **chroma_manager.py**: Gestion ChromaDB
- **parent_store_manager.py**: Gestion JSON store des parents

#### 3. Module `scraper/` (Scraping)

- **haproxy_scraper.py**: Scraper HAProxy docs
- **html_structure_analyzer.py**: Analyse hi√©rarchie HTML
- **compare_with_reference.py**: Comparaison vs projet principal

#### 4. Module `app/` (Interface utilisateur)

- **rag_system.py**: Syst√®me RAG agentic
- **chat_interface.py**: Interface de chat Gradio
- **gradio_app.py**: Application Gradio
- **document_manager.py**: Gestionnaire de documents

#### 5. Scripts de pipeline

- **00_rebuild_agentic.py**: Orchestrateur principal
- **01_scrape_verified.py**: Scraping + validation
- **02_chunking_parent_child.py**: Chunking hi√©rarchique
- **03_indexing_chroma.py**: Indexation ChromaDB
- **04_agentic_chatbot.py**: Chatbot Gradio

### Flux de donn√©es

```
User Question
    ‚Üì
Gradio ChatInterface
    ‚Üì
AgenticRAGSystem.query()
    ‚Üì
LangGraph State
    ‚Üì
Nodes: summarize ‚Üí analyze ‚Üí human_input ‚Üí agent
    ‚Üì
Tools: search_child_chunks ‚Üí retrieve_parent_chunks ‚Üí validate_haproxy_config
    ‚Üì
ChromaDB (similarity_search / MMR)
    ‚Üì
ParentStore (load_parent)
    ‚Üì
Response with sources
    ‚Üì
Gradio Chatbot
```

---

## M√©triques et Performance

### M√©triques de qualit√©

```python
METRICS = {
    "answer_quality_score": "Score 0-1 √©valu√© par LLM judge",
    "retrieval_precision": "% chunks pertinents (√©valuation manuelle)",
    "parent_child_utilization_rate": "% r√©ponses utilisant chunk parent",
    "clarification_rate": "% questions d√©clenchant human-in-the-loop",
    "response_time_p50_sec": "M√©diane temps de r√©ponse",
    "response_time_p95_sec": "95e percentile",
    "source_citation_rate": "% r√©ponses avec citation de section"
}
```

### Param√®tres de performance

```python
# Chunking
CHILD_CHUNK_SIZE = 500        # Taille chunks enfants
CHILD_CHUNK_OVERLAP = 80      # Chevauchement
MIN_PARENT_SIZE = 100         # Taille minimale parent
MAX_PARENT_SIZE = 4000        # Taille maximale parent

# Retrieval
SCORE_THRESHOLD = 0.7         # Distance cosine
DEFAULT_K_CHILD = 5           # Nombre de chunks enfants
DEFAULT_K_MMR = 5             # Nombre de r√©sultats MMR
MMR_FETCH_K = 20              # Pool pour diversification MMR
```

### Exigences de qualit√©

- **Couverture parent/child**: >= 90%
- **Couverture contenu vs projet principal**: >= 95%
- **Taille parents**: 90% dans [100, 4000] chars
- **Taille children**: 90% dans [100, 800] chars
- **Tests**: 100% PASS avant passage √† phase suivante

---

## Commandes Rapides

### Installation
```bash
cd agentic_rag
uv sync
```

### Pipeline complet
```bash
uv run python 00_rebuild_agentic.py
```

### Chatbot
```bash
uv run python 04_agentic_chatbot.py
```

### Tests
```bash
uv run pytest -v
```

### Formatage
```bash
uv run ruff check --fix .
uv run ruff format .
```

---

## Ressources

- [Documentation HAProxy 3.2](https://docs.haproxy.org/3.2/)
- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [Gradio Documentation](https://www.gradio.app/docs)
- [Ollama Documentation](https://ollama.com/docs)

---

## Support

Pour toute question ou probl√®me:
1. Consultez ce guide
2. V√©rifiez les logs dans la console
3. Consultez la documentation officielle des composants

---

**Version**: 1.0.0  
**Date**: 2025-02-28  
**Auteur**: Kilo Code
