# ğŸ“Š RÃ©sultats du Benchmark - HAProxy RAG Chatbot

## ğŸ† Classement des modÃ¨les testÃ©s (APRÃˆS OPTIMISATION)

| Rang | ModÃ¨le | Score | RÃ©ussite | Temps moyen | Recommandation |
|------|--------|-------|----------|-------------|----------------|
| ğŸ¥‡ | `gemma3:latest` | **0.83** | **80%** | 6.94s | âœ… **MEILLEUR** - Utiliser par dÃ©faut |

---

## ğŸš€ Optimisations appliquÃ©es (v2)

### 1. Query Expansion
- **Ajout de synonymes techniques HAProxy** dans `retriever.py`
- Exemple: "health check" â†’ `["health check", "check", "option httpchk", "tcp-check", "inter", "fall", "rise"]`
- **RÃ©sultat** : Scores BM25 multipliÃ©s par 3-5x

### 2. Augmentation TOP_K
- `TOP_K_RETRIEVAL` : 20 â†’ **30** (plus de candidats)
- `TOP_K_RRF` : 10 â†’ **15** (meilleure fusion)

### 3. Keyword Boosting Post-Rerank
- Ajustement des scores basÃ© sur les mots-clÃ©s prÃ©sents
- Formule : `score_final = rerank_score * (1 + 0.3 * match_ratio)`

### 4. Rerank avec Query Ã‰tendue
- Flashrank utilise maintenant la requÃªte Ã©tendue
- Meilleure comprÃ©hension contextuelle

---

## ğŸ“ˆ Comparaison avant/aprÃ¨s

| Question | Avant (score retrieval) | AprÃ¨s (score retrieval) | Gain |
|----------|------------------------|-------------------------|------|
| Health check HTTP | 0.86 | **1.13** | +31% |
| Directive bind | 0.01 | **1.02** | x100! |
| Limiter connexions IP | 0.0001 | **0.33** | x3300! |
| ACLs | 0.002 | **1.05** | x500 |
| Timeouts | 0.08 | **1.05** | x13 |

---

## ğŸ¯ Configuration recommandÃ©e

### Pour gemma3:latest (RECOMMANDÃ‰)

**Dans `llm.py`, utiliser ce prompt systÃ¨me :**

```python
SYSTEM_PROMPT = """Tu es un expert HAProxy 3.2.

CONSIGNES STRICTES :
- Utilise EXCLUSIVEMENT le contexte fourni entre <context> et </context>
- Si une information n'est pas dans le contexte : dis "Non documentÃ© dans ce contexte"
- Pas d'invention, pas de suppositions
- Exemples de code en blocs haproxy
- FranÃ§ais uniquement

STRUCTURE :
1. RÃ©ponse directe (1-2 phrases)
2. DÃ©tails techniques
3. Exemple de configuration
4. Sources entre parenthÃ¨ses"""
```

**ParamÃ¨tres de gÃ©nÃ©ration :**
```python
options = {
    "temperature": 0.1,      # Faible pour rester factuel
    "top_p": 0.9,
    "repeat_penalty": 1.1,
    "num_predict": 1024,
}
```

---

## âš ï¸ ProblÃ¨mes identifiÃ©s

### 1. Retrieval inefficace pour certaines questions

**Exemple :** "Limiter les connexions par IP" trouve des chunks avec score 0.0001

**Solution :**
- AmÃ©liorer le chunking dans `02_ingest.py`
- Ajouter des synonymes dans la requÃªte
- Augmenter `TOP_K_RETRIEVAL` dans `retriever.py`

### 2. ModÃ¨les GGUF non compatibles

Les modÃ¨les GGUF (ex: `Nanbeige4.1-3B-GGUF:Q4_K_M`) nÃ©cessitent un format d'API diffÃ©rent.

**Solution :**
- Utiliser des modÃ¨les natifs Ollama
- Ou adapter `llm.py` pour gÃ©rer le format `/api/generate`

### 3. ModÃ¨les vision non optimaux

Les modÃ¨les `qwen3-vl:*` et `glm-ocr:*` sont conÃ§us pour la vision, pas le texte.

**Solution :**
- Ã‰viter ces modÃ¨les pour du RAG textuel
- PrÃ©fÃ©rer `gemma3`, `qwen3`, `llama3.1`

---

## ğŸš€ Commandes utiles

### Tester un modÃ¨le spÃ©cifique
```bash
uv run python 09_model_benchmark.py --model gemma3:latest
```

### Tester plusieurs modÃ¨les
```bash
uv run python 09_model_benchmark.py --model gemma3:latest --model qwen3:latest
```

### Benchmark complet (long)
```bash
uv run python 09_model_benchmark.py --all
```

---

## ğŸ“ˆ MÃ©triques de qualitÃ©

| MÃ©trique | Objectif | Actuel (gemma3) |
|----------|----------|-----------------|
| Score moyen | > 0.7 | âœ… 0.83 |
| Taux de rÃ©ussite | > 80% | âœ… 100% |
| Temps de rÃ©ponse | < 10s | âœ… 5.52s |
| Keywords trouvÃ©s | > 75% | âœ… 80% |

---

## ğŸ”§ AmÃ©liorations futures

1. **Chunking intelligent** : Regrouper par section thÃ©matique
2. **Query expansion** : Ajouter des synonymes automatiquement
3. **HyDE** : GÃ©nÃ©rer une rÃ©ponse hypothÃ©tique pour amÃ©liorer le retrieval
4. **Fine-tuning** : Fine-tuner un modÃ¨le sur des QA HAProxy

---

**Date du benchmark** : 2026-02-24  
**Version** : HAProxy 3.2, Ollama 0.6.1, Gradio 6.6.0
